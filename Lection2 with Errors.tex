\documentclass[11 pt,russian]{article}
\renewcommand{\baselinestretch}{1}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage[pdftex]{graphicx}
\usepackage{graphics}
\geometry{verbose,letterpaper,tmargin=0.5 cm,bmargin=0.8 cm,lmargin=1cm,rmargin=1cm,headsep=1cm}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{10 pt}
\usepackage{textcomp}
\usepackage{cmap}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{setspace}
\usepackage{indentfirst}
\usepackage[russian]{babel}
\begin{document}
\newenvironment{enumerate*}%
  {\begin{enumerate}%
    \setlength{\itemsep}{1pt}%
    \setlength{\parskip}{1pt}}%
  {\end{enumerate}}
  \newtheorem{Th}{Теорема}
    \newtheorem{Lemm}{Лемма}
  \theoremstyle{definition}
  \newtheorem{Rem}{Замечание}
  \newtheorem{Que}{Вопрос}
  \newtheorem{Exam}{Пример}
    \newtheorem{Def}{Определение}
\setcounter{section}{1}
\section{Условная вероятность. Независимость}
Сегодня мы будем рассматривать пространства с, вообще говоря, бесконечным числом элементарных исходов, но не более чем счетным. 
При этом мы дополнительно требуем от вероятности выполнения свойства счетной аддитивности
$$
{\bf P}(A_1 + \dotsb + A_n +\dotsb) = \sum_{n=1}^{\infty} {\bf P}(A_n). 
$$
Как и прежде мы будем задавать набор вероятностей $p_i$ элементарных исходов, в сумме дающих единицу:
$$
\sum_{i=1}^{\infty} p_i = 1.
$$
Отсюда автоматически задается вероятность любого события
$$
{\bf P}(A) = \sum_{k:\ \omega_k\in A} {\bf P}(\omega_k) = \sum_{k:\ \omega_k\in A} p_k,
$$
только теперь сумма может быть бесконечной.
\subsection{Введение}
Наше представление о вероятности события зависит от нашей информированности. Вероятность того, что у моего соперника среди пяти карт будет туз пик равна 5/52. Если я знаю 5 карт в своей руке, то эта вероятность уже 5/47 (или 0, конечно же). А если я помню три карты, которые обменял ходом раньше, то уже 5/44. А если у него за спиной стоит зеркало и я вижу там туза пик, то она равна 1. 

В наш век информации мы постоянно получаем новые сведения, которые в силу вышесказанного, меняют нашу вероятность. Сегодня мы поговорим о том, как работать в вероятностной модели в условиях поступающей информации.
\subsubsection{Классический случай}
Пусть $\Omega=\{\omega_1,\dotsc,\omega_N\}$ --- конечное пространство элементарных исходов с классически заданной вероятностью ${\bf P}(\omega_i) = 1/N$. Тогда вероятность события $A$ определяется соотношением
$$
{\bf P}(A) = \frac{|A|}{N}.
$$
Предположим, что мы узнали о том, что выполнено событие $B$. Тогда $B$ становится нашим новым вероятностным пространством, а наше событие $A$ превращается в $A\cap B$. При этом из соображений симметрии все исходы остаются равновероятными, поэтому
$$
{\bf P}_B(A) = \frac{|A\cap B|}{|B|}.
$$ 
Можно заметить, что можно записать эту вероятность и в старых терминах.
$$
{\bf P}_{B}(A) =  \frac{|A\cap B|/N}{|B|/N} =  \frac{{\bf P}(AB)}{{\bf P}(B)}.
$$
Итак, вероятность $A$ ''при условии, что случилось $B$'' задается формулой ${\bf P}(AB)/{\bf P}(B)$.
\subsubsection{''Рациональный'' случай}
Пусть $(\Omega,\mathcal{F},{\bf P})$ --- вероятностное пространство, где $\Omega=\{\omega_1,\dotsc,\omega_N\}$ --- конечное пространство элементарных исходов, вероятности исходов равны $p_1,\dotsc,p_N$, соответственно, где $p_1=a_1/b_1,\dotsc,p_N = a_N/b_N$ --- рациональные числа. 

Введем новое пространство $\widetilde{\Omega} = \{\widetilde{\omega}_1,\dotsc,\widetilde{\omega}_M\}$, где $M = b_1 \dotsm b_N$, первые $a_1 b_2 \dotsm. b_N$ новых исходов в объединении дают $\omega_1$,  вторые $b_1 a_2 b_3 \dotsm b_N$ --- $\omega_2$ и так далее. Если мы определим вероятность $\widetilde{{\bf P}}$ на пространстве $\widetilde{\Omega}$ классическим образом, то $(\Omega,\mathcal{F},{\bf P})$ и $(\widetilde{\Omega},\widetilde{\mathcal{F}},\widetilde{P})$ окажутся согласованными --- любом событие $A$ имеет ту же вероятность ${\bf P}(A)$, что и соответствующее ему событие $\widetilde{A}$ из $\widetilde{\mathcal{F}}$. 
\begin{figure}[h!]
\caption{Пример разбиения пространства с неклассически заданной вероятностью}
   \begin{center}
   \includegraphics[width=10cm,height=4cm,keepaspectratio]{SpaceDivision.png}
   \end{center}
\end{figure}
Иначе говоря, мы разбили каждый исход в старом пространстве $\Omega$ на части так, чтобы они получились равной вероятности.

Не так важно, как это реализовано физически, для нас существенно, что нашему пространству соответствует пространству с классически определенной вероятностью, на котором соображения симметрии и равноправия позволяют понять как надо определять вероятность. Мы будем прибегать к этому мысленному эксперименту и впредь --- если мы хотим определить какое-то понятия с физически понятным подтекстом, то мы будем естественным образом определять его на классическом пространстве, а затем переносить его на произвольное. 

В пространстве $\widetilde{\Omega}$ мы определяем вероятность события $A$ ''при условии, что случилось $B$'' формулой $\widetilde{{\bf P}}(AB)/\widetilde{{\bf P}}(B)$. Значит, в старом пространстве естественно определять ее формулой
$$
\frac{{\bf P}(AB)}{{\bf P}(B)}.
$$
\subsection{Условная вероятность}
\label{CondProb}
Естественным образом, та же формула будет сохраняться и для иррациональных вероятностей исходов. Итак,
\begin{Def}
{\it Условной вероятностью} события $A$ при условии $B$ называют
$$
{\bf P}(A|B):= \frac{{\bf P}(A B)}{{\bf P}(B)}.
$$
Здесь предполагается, что ${\bf P}(B)> 0$. 
\end{Def}
Если рассуждения предыдущего раздела вам не понравились, то вы можете просто пропустить их и считать, что это определение и всё тут.

Содержательно мы понимаем под условной вероятностью вероятность события $A$, когда мы уже знаем, что случилось $B$.
\begin{Que}
При броске трех костей выпали три четных числа. Какая вероятность, что в сумме выпало 6 очков?
a) 1/27;\\
b) 2/9;\\
c) 1/81;\\
d) 5/72.
\end{Que}
\begin{Exam}
Пусть в урне 15 шаров из которых 5 белых и 10 черных шаров, мы выбираем три шара без возвращения. Пусть $A$ --- событие ''первый шар белый'', $B$ --- событие ''второй шар белый'', $C$ --- событие ''третий шар черный''. Какая вероятность события B, если известно, что случилось событие B? Какая вероятность события C, если известны A и B?

Пространство элементарных исходов имеет вид 
\begin{eqnarray*}
\Omega = \{(i,j,k), i\neq j, i\neq k, j\neq k, i,j,k\in \{1,\dotsc,15\}\}, \quad
A = \{(i,j,k)\in \Omega: i\in \{1,\dotsc,5\}\}, \\
B = \{(i,j,k)\in \Omega: j\in \{1,\dotsc,5\}\}, \quad
C = \{(i,j,k)\in \Omega: k\in \{6,\dotsc,15\}\}.
\end{eqnarray*}
Тогда
$$
{\bf P}(A) = \frac{5\cdot 14\cdot 13}{15\cdot 14\cdot 13} = \frac13,\quad {\bf P}(AB) = \frac{5\cdot 4\cdot 13}{15\cdot 14\cdot 13} = \frac{2}{21},\quad {\bf P}(ABC) = \frac{5\cdot 4\cdot 10}{15 \cdot 14 \cdot 13} = \frac{10}{39}.
$$
Следовательно,
$$
{\bf P}(B|A) = \frac{5\cdot 4\cdot 13}{5\cdot 14 \cdot 13} = \frac{4}{14},\quad
{\bf P}(C|AB) = \frac{5 \cdot 4 \cdot 10}{5\cdot 4\cdot 13} = \frac{10}{13}.
$$
Ответы совпадают с нашими ожиданиями. Действительно, вероятность $B$ при условии $A$ --- это вероятность вытянуть белый шар вторым из урны в мире, в котором первым вытянутым шар был белым. В этом мире в урне перед вторым вытягиванием было 14 шаров, из которых 4 белых. Точно также вероятность $C$ при условии $AB$ --- это вероятность вытянуть черный шар из урны, где 10 черных и 3 белых шара. 

Зачастую хочется записать что-то в духе двойной условной вероятности ${\bf P}((C|B)|A)$ (так писать неправильно!)  --- вероятность, что случится $C$, если уже случилось $B$, а перед этим случилось $A$. Однако, это просто ${\bf P}(C|AB)$ как из формального определения, так и из его физической интерпретации.
\end{Exam}
Как мы видим из примера c шарами, зачастую мы легко можем найти условные вероятности (потому что легко работаем в новой реальности, заданной условием), а вот вероятности пересечения нам получить сложнее. В связи с этим полезно перевернуть определение условной вероятности:
$$
{\bf P}(AB) = {\bf P}(A|B) {\bf P}(B).
$$
Аналогичный результат можно доказать в случае $n$ событий $A_1,\dotsc,A_n$:
$$
{\bf P}(A_n \dotsm A_1) = {\bf P}(A_n|A_{n-1}\dotsm A_1) \dotsm {\bf P}(A_2|A_1) {\bf P}(A_1).
$$
Этот результат называют теоремой умножения.
\begin{proof}
Докажем этот факт по индукции. При $n=2$ он верен. 

Пусть при $n=k$ он верен, докажем его при $n=k+1$. В силу предположения и базы индукции
$$
{\bf P}(A_{k+1}\dotsm A_1) = {\bf P}(A_{k+1}|A_k \dotsm A_1) {\bf P}(A_k \dotsm A_1) = {\bf P}(A_{k+1}|A_k) {\bf P}(A_k|A_{k-1}) \dotsm {\bf P}(A_2|A_1) {\bf P}(A_1),
$$
что и требовалось доказать.
\end{proof}
Эту формулу удобно использовать для подсчета вероятностей пересечения событий.
\begin{Que}
Чему равна вероятность того, что при трех вытягиваниях без возвращения из урны с 8 черными, 5 белыми и 3 красными шарами, мы вытянем черный, белый и снова черный шары.\\
a) 1/12\\
b) 5/64\\
c) 1/27\\
d) 4/21.
\end{Que}
\subsection{Формула полной вероятности и формула Байеса}
{\bf в этом разделе спрятана маленькая опечатка в записи}
\begin{Exam}
Предположим, что мы хотим найти вероятность события $B$: второй шар, взятый из урны с 5 белыми и 10 черными шарами, будет белым. 

Давайте разберемся какой шар выпал первым. Пусть $A$ --- событие, заключающееся в том, что первый шар белый. Мы легко можем найти
$$
{\bf P}(A B) = {\bf P}(B|A) {\bf P}(A) = \frac{5}{15}\ \frac{4}{14} = \frac{2}{21},\quad {\bf P}(\overline{A} B) = {\bf P}(B|\overline{A}) {\bf P}(\overline{A}) = \frac{10}{15}\ \frac{5}{14} = \frac{5}{21},
$$
откуда 
$$
{\bf P}(B) = {\bf P}(B|A) {\bf P}(A) + {\bf P}(B|\overline{A}) {\bf P}(\overline{A}) = \frac{2}{21} + \frac{5}{21} = \frac{7}{21}=\frac13.
$$
Мы уже знаем этот ответ с прошлого занятия: вероятность, что второй шар белый та же, что и для первого. Но теперь мы получили новый инструмент получения такой формулы.
\end{Exam}
В общем случае аналогичная формула также справедлива. Сформулируем ее.
\begin{Def}
События $B_1,\dotsc,B_N$ называются разбиением, если 
$$\Omega = \bigcup_{n=1}^{N} B_n,$$
то есть если $B_i$ не пересекаются, и их объединение есть все $\Omega$. Мы предполагаем, что $N$ может быть конечным или бесконечным.
\end{Def}

Пусть $B_1,B_2,\dotsc.$ --- события c ненулевой вероятностью, образующие разбиение $\Omega$. Тогда
$$
{\bf P}(A) = {\bf P}\left(\sum_{i=1}^{n} A\cap B_i\right) =
 \sum_{i=1}^{n} {\bf P}(AB_i) = \sum_{i=1}^{n} {\bf P}(A|B_i){\bf P}(B_i).
$$
Это соотношение называют {\it формулой полной вероятности}. Если число событий счетно, то формула остается в силе, но конечная сумма превращается в ряд.

Почему эта формула так полезна? Она позволяет посчитать вероятность в сложно устроенных экспериментах. 
\begin{Exam}
Пусть мы взяли то ли монету, на сторонах которой орел и решка, то ли монету, на сторонах которой два орла (равновероятно). Какая вероятность, что при трех бросаниях выпадет три орла?

Положим $A$ -- выпало 3 орла, $B_1$ -- монета с орлом и решкой, $B_2$ -- монета с двумя орлами. При этом 
$$
{\bf P}(A) = {\bf P}(A|B_1) {\bf P}(B_1) + {\bf P}(A|B_2) {\bf P}(B_2) = \frac{1}{8} \cdot \frac12 + 1\cdot \frac12 = \frac{9}{16}.
$$ 
\end{Exam}
Как мы видим, с помощью формулы полной вероятности можно свести сложную задачу к нескольким простым, не погружаясь в запутанное конструирование общего вероятностного пространства.
\begin{Que}
Мы подбрасываем монету c вероятностью орла $1/3$. Если она выпадает на решку, то мы вытаскиваем шар из урны с 3 белыми и 7 черными шарами, а если на орла, то из урны с 9 белыми и 1 черным шаром. Какая вероятность того, что мы вытащим белый шар?\\
a) $3/5$\\
b) $7/10$.\\
c) $2/5$.\\
d) $1/2$.
\end{Que}
Отметим еще одну формулу, легко вытекающую из формулы полной вероятности. Предположим, что мы знаем ${\bf P}(B_1),\dotsc,{\bf P}(B_n)$ для разбиения $B_1, \dotsc ,B_n$. Пусть также известны ${\bf P}(A|B_1),\dotsc,{\bf P}(A|B_n)$. Тогда 
$$
{\bf P}(B_1|A) = \frac{{\bf P}(A|B_1) {\bf P}(B_1)}{{\bf P}(A)} = \frac{{\bf P}(A|B_1) {\bf P}(B_1) }{\sum_{i=1}^{n} {\bf P}(A|B_i) {\bf P}(B_i)}.
$$
Данная формула называется формулой Байеса.
\begin{Exam}
Представим, что в последнем вопросе мы видим, что шар белый, и хотим восстановить на что упала монета. Тогда если $B_1$ --- монета упала на орла, $A$ --- шар белый, 
то
$$
{\bf P}(B_1|A) = \frac{{\bf P}(A|B_1) {\bf P}(B_1)}{{\bf P}(A|B_1) {\bf P}(B_1)+{\bf P}(A|\overline{B_1}) {\bf P}(\overline{B_1})} = \frac{\frac13 \cdot \frac{9}{10}}{\frac13 \cdot \frac{9}{10} + \frac23 \cdot \frac{3}{10}} = \frac{3}{5}.
$$
После вытягивания белого шара вероятность того, что монета упала на орла сильно возросла --- от 0.(3) до 0.6, то есть почти вдвое.
\end{Exam}
\begin{Exam}
Представим, что тест на определение болезни с вероятностью 99\% определяет больным больного, с вероятностью 2\% определяет здорового больным. При этом среди населения 1\% больных людей. Человек сдал тест и тот определил его больным. Какая вероятность того, что он действительно болен?

Положим $B_1$ -- человек болен, $B_2$ -- здоров, $A$ -- тест признал человека больным. Заметим, что
$$
{\bf P}(B_1) = 0.01,\quad
{\bf P}(B_2) = 0.99, \quad
{\bf P}(A|B_1) = 0.99,\quad
{\bf P}(A|B_2) = 0.02.
$$
Следовательно,
$$
{\bf P}(B_1|A) = \frac{{\bf P}(A|B_1) {\bf P}(B_1)}{{\bf P}(A|B_1) {\bf P}(B_1) + {\bf P}(A|B_2) {\bf P}(B_2)} = \frac{0.01 0.99}{0.01 0.99 + 0.99 0.02} = \frac{1}{3}.
$$
Несмотря на достаточную надежность теста, редкость болезни снижает шансы верного определения больных. Можно представить себе 100 случайных человек: из них всего 1 в среднем болен (и тест, вероятно, признает его больным), а 99 здоровы и тест в среднем 2 из них назовет больными.
\end{Exam}
\subsection{Независимость}
Это понятие является ключевым для развития теории вероятностей в отдельности от общей теории меры. Итак, дадим следующее естественное определение.
\begin{Def}
События $A$ и $B$ называются независимыми, если ${\bf P}(A|B) = {\bf P}(A)$ или ${\bf P}(B)=0$.
\end{Def}
Это определение в силу определения условной вероятности переписывается в виде
\begin{Def}
События $A$ и $B$ называются независимыми, если ${\bf P}(AB) = {\bf P}(A) {\bf P}(B)$.
\end{Def}
Второе определение чаще всего удобнее для проверки и мы будем использовать его.

Начнем с нескольких простых замечаний, которые вам предстоит доказать самостоятельно:\\
{\bf Кроме одного, которое неверно}
\begin{itemize}
\item Если $A$ и $B$ независимы, то $A$ и $\overline{B}$ независимы, $B$ и $\overline{A}$ независимы, $\overline{A}$ и $\overline{B}$ независимы
\item События вероятности 0 и 1 независимы от любых событий.
\item Событие независимо от самого себя только если оно имеет вероятность 0 или 1.
\item Непересекающиеся события независимы только если одно из них имеет вероятность 0.
\item Если $A$ не зависит от $B$ и $A$ независит от $C$, где $BC=\emptyset$, то $A$ независит от $B+C$.
\item $A$ не зависит от $\overline{A}$.
\end{itemize}
{\bf Чуть ниже что-то не так}

Нам понадобится более общее определение независимости $n$ событий.
\begin{Def}
События $A_1,\dotsc,A_n$ --- независимы (в совокупности), если
$${\bf P}(A_1 \dotsm A_n) = {\bf P}(A_1) \dotsm {\bf P}(A_n).
$$
\end{Def}
Давайте поймем почему нужно такое сложное определение. Неужели не хватит просто независимости каждого события с каждым (такую независимость называют попарной)?
\begin{Exam}
Предположим, что мы бросаем симметричную монету дважды. Рассмотрим события A = \{первый бросок оказался на орла\}, B = \{второй бросок оказался на орла\}, C = \{ровно один бросок оказался на орла\}. Тогда 
$$
{\bf P}(A|B) = {\bf P}(A) = \frac12,\ 
{\bf P}(C|A) = {\bf P}(C) = \frac12,\
{\bf P}(C|B) = {\bf P}(C) = \frac12.
$$
Поэтому каждые два события независимы. Однако,
$$
{\bf P}(ABC) = 0 \neq {\bf P}(A) {\bf P}(B) {\bf P}(C) = \frac18.
$$
Поэтому каждое из событий не влияет на шансы каждого из других случиться, но два события вместе делают невозможным третье.

Точно также можно построить $n$ событий, любые $n-1$ из которых независимы, а все $n$ вместе зависимы.
\end{Exam}
{\bf Даже не трогая доказательство -- тут не все чисто\\ }
Можно привести следующий критерий независимости, обобщающий первое свойство независимости двух событий, указанное выше:
\begin{Lemm}
\label{LemmDelt}
События $A_1,\dotsc,A_n$ независимы тогда и только тогда, когда 
\begin{equation}
\label{L2-Th2}
{\bf P}\left(A_1^{\delta_1} \dotsm A_n^{\delta_n}\right) = {\bf P}\left(A_1^{\delta_1}\right) \dotsm {\bf P}\left(A_n^{\delta_n}\right),
\end{equation}
при всех $\delta_i\in \{0,1\}$, $A^{1}=A$, $A^0=1$.
\end{Lemm}
\begin{proof}(Не входит в программу экзамена).

1) Докажем достаточность. Пусть $A_1,\dotsc,A_n$ независимы. Покажем большее, чем нам требуется --- что
$$
{\bf P}(A_{i_1}^{\delta_{i_1}} \dotsm A_{i_l}^{\delta_{i_l}}) = {\bf P}(A_{i_1}^{\delta_{i_1}}) \dotsm {\bf P}(A_{i_l}^{\delta_{i_l}})
$$ 
при любых $l$, $1\le i_1 < \dotsc < i_l\le n$, $\delta_{i_1},\dotsc,\delta_{i_l}\in \{0,1\}$. 
Доказательство проведем индукцией по $k=l-(\delta_{i_1}+\dotsb.+\delta_{i_l})$.

База индукции: при $k=0$ утверждение вытекает из того, что $A_1,\dotsc,A_n$ независимы.

Переход индукции: пусть при $k\le m$ при некотором $m$ утверждение доказано, докажем при $k=m+1$. Без ограничения общности считаем $\delta_{i_1} = 0$. Тогда
\begin{equation}
\label{L2-Th2-1}
{\bf P}\left(A_{i_1}^{0} A_{i_2}^{\delta_{i_2}} \dotsm A_{i_l}^{\delta_{i_l}}\right) = {\bf P}\left(A_{i_2}^{\delta_{i_2}} \dotsm A_{i_l}^{\delta_{i_l}}\right) - {\bf P}\left(A_{i_1}^{1} A_{i_2}^{\delta_{i_2}} \dotsm A_{i_l}^{\delta_{i_l}}\right) 
\end{equation}
при любых $i_1,\dotsc,i_l$. В силу предположения индукции
\begin{equation}
\label{L2-Th2-2}
{\bf P}\left(A_{i_2}^{\delta_{i_2}} \dotsm A_{i_l}^{\delta_{i_l}}\right) = {\bf P}\left(A_{i_2}^{\delta_{i_2}}\right) \dotsm {\bf P}\left(A_{i_l}^{\delta_{i_l}}\right),\
{\bf P}\left(A_{i_1}^{1} A_{i_2}^{\delta_{i_2}} \dotsm A_{i_l}^{\delta_{i_l}}\right) = {\bf P}\left(A_{i_1}^{1}\right) {\bf P}\left(A_{i_2}^{\delta_{i_2}}\right) \dotsm {\bf P}\left(A_{i_l}^{\delta_{i_l}}\right).
\end{equation}
Подставляя~(\ref{L2-Th2-2}) в~(\ref{L2-Th2-1}), получаем
$$
{\bf P}\left(A_{i_1}^{0} A_{i_2}^{\delta_{i_2}} \dotsm A_{i_l}^{\delta_{i_l}}\right) = \left(1 - {\bf P}\left(A_{i_1}\right)\right) {\bf P}\left(A_{i_2}^{\delta_{i_2}}\right) \dotsm {\bf P}\left(A_{i_l}^{\delta_{i_l}}\right) =
{\bf P}\left(A_{i_1}^0\right) {\bf P}\left(A_{i_2}^{\delta_{i_2}}\right) \dotsm {\bf P}\left(A_{i_l}^{\delta_{i_l}}\right).
$$
Достаточность показана.\\
2) Докажем необходимость. Пусть мы знаем~(\ref{L2-Th2}) для любого набора $i_1,\dotsc, i_n$. Докажем, что 
$$
{\bf P}\left(A_{i_1} \dotsm A_{i_l}\right) = {\bf P}\left(A_{i_1}\right) \dotsm {\bf P}\left(A_{i_l}\right)
$$
при всех $l\le n$. Для удобства будем считать, что $i_1=1,\dotsc,i_l=l$ (это вопрос нумерации $A_i$). Тогда
\begin{eqnarray*}
{\bf P}\left(A_1 \dotsm A_l\right) = \sum_{\delta_{l+1},\dotsc,\delta_n\in \{0,1\}} {\bf P}\left(A_1 \dotsm A_l A_{l+1}^{\delta_{l+1}} \dotsm A_n^{\delta_n}\right) = 
\sum_{\delta_{l+1},\dotsc,\delta_n\in \{0,1\}} {\bf P}\left(A_1\right) \dotsm {\bf P}\left(A_l\right) {\bf P}\left(A_{l+1}^{\delta_{l+1}}\right) \dotsm {\bf P}\left(A_n^{\delta_n}\right) =\\
{\bf P}\left(A_1\right) \dotsm {\bf P}\left(A_l\right) \sum_{\delta_{l+1},\dotsc,\delta_n\in \{0,1\}} {\bf P}\left(A_{l+1}^{\delta_{l+1}}\right) \dotsm {\bf P}\left(A_n^{\delta_n}\right).
\end{eqnarray*} 
Остается показать, что сумма в правой части равна единице. Для этого заметим, что это в точности
$$
\left({\bf P}\left(A_{l+1}^0\right) + {\bf P}\left(A_{l+1}^{1}\right)\right)\dotsm\left({\bf P}\left(A_{n}^0\right) + {\bf P}\left(A_{n}^{1}\right)\right) = 1 \cdot 1 \dotsm \cdot 1 = 1.
$$
Лемма доказана.
\end{proof}
Данная лемма удобна тем, что позволяет рассматривать только $n$ событий, не рассматривая все поднаборы, что требует определение независимости.
\subsection{Ответы на вопросы}
\begin{enumerate}
\item Наше пространство состоит из пар $(2i,2j)$, $i,j\in \{1,2,3\}$, следовательно в нем 9 исходов. Нам подходят 3 пары $(2,6)$, $(4,4)$, $(6,2)$. Итого 1/3.
\item В силу теоремы произведения
$$
\frac{8}{16} \cdot \frac{5}{15} \cdot \frac{7}{14} = \frac{1}{12}.
$$
\item В силу формулы полной вероятности искомая вероятность есть
$$
\frac23 \cdot \frac{3}{10} + \frac13 \cdot \frac{9}{10} = \frac{5}{10} = \frac12.
$$
\end{enumerate}
\end{document}
