\documentclass[11 pt,russian]{article}
\renewcommand{\baselinestretch}{1}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage[pdftex]{graphicx}
\usepackage{graphics}
\geometry{verbose,letterpaper,tmargin=0.5 cm,bmargin=0.8 cm,lmargin=1cm,rmargin=1cm,headsep=1cm}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{10 pt}
\usepackage{textcomp}
\usepackage{cmap}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{setspace}
\usepackage{indentfirst}
\usepackage[russian]{babel}
\begin{document}
\newenvironment{enumerate*}%
  {\begin{enumerate}%
    \setlength{\itemsep}{1pt}%
    \setlength{\parskip}{1pt}}%
  {\end{enumerate}}
  \newtheorem{Th}{Теорема}
  \theoremstyle{definition}
  \newtheorem{Rem}{Замечание}
  \newtheorem{Que}{Вопрос}
  \newtheorem{Exam}{Пример}
    \newtheorem{Def}{Определение}
\section{Вероятностное пространство}
Начнем с такого вопроса, чтобы проверить вашу вероятностную интуцию:
\begin{Que}
Какое из событий более вероятно при бросании симметричной монеты:\\
(a) выпадет орел, орел, орел, решка, решка, решка;\\
(b) выпадет решка, решка, решка;\\
(c) выпадет орел, решка, орел, решка, орел, решка;\\
(d) (a) и (b) вместе.
\end{Que}
\subsection{Введение}
Если спросить у вас что такое вероятность какого-либо события, то, скорее всего, вы дадите эмпирическое определение --- вероятность события есть доля случаев, в которых оно произойдет, если много раз его повторять.

Это определение полностью соответствует нашим интуитивным представлениям о вероятности. Однако, с точки зрения науки оно не слишком удачно. Вот лишь два из множества вопросов, на которые достаточно затруднительно ответить с точки зрения эмпирического определения.
\begin{enumerate*}
\item Что такое повторение?\\
Допустим, я вытащил карту наугад из колоды карт. Теперь я планирую перевернуть верхнюю карту и хочу узнать какая вероятность того, что это дама пик.\\
С точки зрения эмпирического определения я должен повторить эксперимент много раз и посмотреть на долю успехов. Но ведь верхняя карта уже есть какая-то, если я буду повторять эксперимент (то есть брать верхнюю карту, смотреть на нее и класть ее обратно), то я всегда буду получать один и тот же результат.\\
Нет, скажете вы, повторять эксперимент нужно более полно --- каждый раз заново раскладывать колоду в случайном порядке и брать верхнюю карту.\\
Однако, попробуйте объяснить в сколько-то общей постановке задачи насколько сильно мне нужно возвращаться в прошлое, чтобы повторить опыт. Нужно ли мне каждый раз покупать новую колоду? Или может быть я должен заново начать эволюцию жизни на Земле, дождаться появления человека, создания печатной промышленности и так далее?\\
Мы интуитивно понимаем о каком именно повторении идет речь (хотя и это не всегда), но включить это в определение достаточно затруднительно. 
\item Как быть с событиями, которые нельзя повторить?\\
Что такое вероятность победы ''Барселоны'' в завтрашнем противостоянии с ''Реал Мадрид''? Мы не сможем повторить этот эксперимент, завтрашний матч случится только один раз. А любой последующий матч уже не будет повторением завтрашнего, это будет другой матч с другими начальными условиями.
\end{enumerate*}
В этом случае математикам остается одно --- отказаться от эмпирического определения вероятности, а считать, что вероятность --- это что-то данное нам изначально. В этой модели, в которой вероятности нам даны, мы можем получить какие-то законы и правила. Одним из таким законов будет, как мы выясним позже, закон больших чисел, %(теорема~\ref{Khinch}),
который и покажет, что вероятность  должна соответствовать эмпирическому определению.
\subsection{Вероятностное пространство} 
\subsubsection{Пространство элементарных исходов}
Итак, пусть у нас есть некоторый опыт, у которого есть несколько (для простоты конечное число N) возможных исходов. Множество возможных исходов мы будем обозначать $\Omega=\{\omega_1,\dotsc,\omega_N\}$ и они будут как-то соответствовать итогам исходного физического опыта. 
\begin{Def}
Такое пространство называется пространством элементарных исходов, а его элементы --- элементарными исходами.
\end{Def}
С математической точки зрения таким пространством может быть произвольное множество (пока мы рассматриваем только конечные $\Omega$, но позже введем в рассмотрение множества произвольной структуры).
\begin{Exam}
Для броска монеты мы можем выбрать $\Omega = \{O, P\}$, где O соответствует орлу, а Р --- решке или, скажем, $\Omega =\{0,1\}$, где 1 соответствует орлу, а 0 --- решке.

Для двух бросков монеты --- 
$\Omega = \{0,1,2,3\}$, где $0,1,2,3$ как-то соответствуют четырем возможным элементарным исходам или, скажем, $\Omega = \{(0,0), (0,1), (1,0), (1,1)\}$, где первая цифра соответствует первому броску, а вторая --- второму.

Описать тот же эксперимент можно и с помощью $\Omega = \{\{0,0\}, \{0,1\}, \{1,1\}\}$, если человек, наблюдающий за опытом, не знает какая из подоброшенных монет первая, а видит лишь результат броска. В этом случае у него будет один исход $\{0,1\}$, описывающий итог эксперимента ''один раз выпал орел, а один раз решка''.

Может быть и гораздо более экзотическое описание эксперимента, например, мы можем наблюдать за взаимным положением молекул монеты в пространстве в наших двух случаях. Тогда у нас будет четыре принципиально разных возможных расположения, соответствующих тому как выпадали монеты. Это пространство покажется нам неестественным, но тоже имеет право на существование.
\end{Exam}
Как мы видим --- в выборе пространства элементарных исходов для описания данного эксперимента есть изрядный произвол. Главное --- включить в него все ситуации, которые меня интересуют. Так, если я хочу заниматься исследованием реальной монеты с высокой точностью, то неплохо бы добавить к возможным исходам броска случай ''монета встала на ребро'' (соответственно, для двух бросков возможных исходов вместо 4 станет 9), а то и добавить исход ''монета потерялась и эксперимент прекратился''.
\begin{Que}
Сколько в этом случае станет возможных элементарных исходов у эксперимента?
\end{Que}

\subsubsection{Алгебра событий}
Чаще всего нас интересуют не отдельные исходы, а целые группы исходов. Иначе говоря, мы рассматриваем подмножества $\Omega$. В нашем простом случае можно рассматривать множество всех подмножеств $2^{\Omega}$ (почему это плохо в более общей постановке мы поговорим позднее). Итак, подмножества $\Omega$ будем называть событиями, а их множество будем обозначать $\mathcal{F}$.
\begin{Exam}
Для одного подбрасывания монеты c $\Omega = \{0,1\}$ мы получим 
$$
\mathcal{F} = \{\emptyset, \Omega, \{0\}, \{1\}\}.
$$
Событие $\emptyset$ называется невозможным, а $\Omega$ --- достоверным. Можно интерпретировать наши 4 события как ''монета выпала ни на что'' (такого не бывает), ''монета на что-то выпала'' (такое происходит всегда), ''монета выпала на орла'', ''монета выпала на решку''. 

Для двух подбрасываний монеты будет уже 16 событий
\begin{eqnarray*}
\mathcal{F} = \{\emptyset, \Omega, \{(0,0)\}, \{(1,0)\}, \{(0,1)\}, \{(1,1)\}, \{(0,0), (0,1)\},  \{(0,0), (1,0)\},  \{(0,0), (1,1)\}, \{(0,1), (1,0)\},  \{(0,1), (1,1)\},\\   \{(1,0), (1,1)\}, \{(0,0), (1,0), (0,1)\}, \{(0,0), (0,1), (1,1)\}, \{(0,0), (1,0), (1,1)\}, \{(0,1), (1,0), (1,1)\}\}.
\end{eqnarray*}
Скажем, событие $\{(0,0), (0,1)\}$ можно назвать ''первый бросок был решкой'', а событие $\{(0,0), (1,0), (0,1)\}$ --- ''выпала хотя бы одна решка''.
\end{Exam}

Для общего случая $\mathcal{F}$ будет состоять из $2^N$ событий. 

Над событиями можно производить те же операции, что и над любыми другими множествами:
\begin{itemize}
\item дополнение $\overline{A}$ (событие не выполнено);
\item объединение $A\cup B$ (выполнено хотя бы одно из событий);
\item пересечение $A\cap B$ (выполнены оба события);
\item разность $A\setminus B$ (выполнено первое событие, но не второе);  
\item симметрическая разность (''выполнено ровно одно из событий'')
$$A\Delta B = (A\setminus B) \bigcup (B\setminus A).$$
\end{itemize}
\begin{figure}[h]
\caption{Операции над множествами}
   \begin{center}
   \includegraphics[width=20cm,height=4cm,keepaspectratio]{SymDiff.png}
   \end{center}
\end{figure}
Мы будем для краткости использовать обозначение $AB$ для пересечения событий $A\cap B$.

Нам также будет полезно обозначение ''сумма событий''. Мы говорим про сумму событий $A+B$, подразумевая под этим $A\bigcup B$, причем с дополнительным предположением, что $AB= \emptyset$. 

Вообще говоря, мы можем рассматривать в качестве множества событий $\mathcal{F}$ не все возможные подмножества $\Omega$, а только их часть, но при этом естественно требовать в случае конечного пространства следующие условия 
\begin{itemize}
\item $\Omega\in\mathcal{F}$; 
\item Если $A\in \mathcal{F}$, то и $\overline{A}\in \mathcal{F}$;
\item Если $A,B\in \mathcal{F}$, то и $A\cup B\in \mathcal{F}$.
\end{itemize}
Такое множество называется алгеброй подмножеств $\Omega$. В силу соотношений
$$
A\cap B = \overline{\overline{A}\cup \overline{B}},\quad
A\setminus B = A\cap \overline{B},\quad
A\Delta B = (A\cap \overline{B})\cup (B\cap \overline{A})
$$
алгебра множеств содержит вместе с каждыми двумя множествами их пересечение, разность и симметрическую разность.
\begin{Exam}
Множество $\{\emptyset, \Omega\}$ --- алгебра подмножеств $\Omega$. Это самая простая (так называемая тривиальная) алгебра событий.

Множество $\{\emptyset, A, \overline{A},\Omega\}$ также будет алгеброй. Эта алгебра называется алгеброй, порожденной $A$. 
\end{Exam}
\subsubsection{Вероятность}
{\bf Последняя ошибка где-то тут\\ }
Каждому событию $A$ сопоставим вероятность ${\bf P}(A)$. 
\begin{Def}
Вероятностной мерой (или просто вероятностью) на конечном пространстве $\Omega$ с алгеброй событий $\mathcal{F}$ называется отображение ${\bf P}:\mathcal{F}\to [0,1]$, удовлетворяющее свойствам
\begin{enumerate*}
\item ${\bf P}(\Omega) = 1$.
\item ${\bf P}(A \bigcup B) = {\bf P}(A) + {\bf P}(B)$.
\end{enumerate*}
\end{Def}
Второе свойство называется аддитивностью. Важно заметить, что в более общем случае бесконечных пространств элементарных исходов нам понадобится еще одно (очень важное) свойство вероятности, но пока мы рассматриваем только конечные пространства, нам хватит и этих двух.

Из определения вероятности можно вывести следующие свойства
\begin{itemize}
\item ${\bf P}(\emptyset) = 0$.
\item ${\bf P}(\overline{A}) = 1 - {\bf P}(A)$.
\item ${\bf P}(A_1+ \dotsb + A_n) = {\bf P}(A_1) + \dotsb + {\bf P}(A_n)$.
\item ${\bf P}(A\cup B) = {\bf P}(A) + {\bf P}(B) - {\bf P}(AB)$.
\item ${\bf P}(A\setminus B) = {\bf P}(A) - {\bf P}(AB)$.
\item ${\bf P}(A\Delta B) = {\bf P}(A) + {\bf P}(B) - 2{\bf P}(AB)$.
\end{itemize}
Попробуйте доказать их самостоятельно. 
\begin{Que}
А верно ли в общем случае соотношение ${\bf P}(AB) = {\bf P}(A) {\bf P}(B)$?
\end{Que}
Приведенная формула для ${\bf P}(A\cup B)$ допускает следующее обобщение:
$$
{\bf P}\left(\bigcup_{i\le n} A_i\right) = \sum_{i\le n} {\bf P}(A_i) - \sum_{i_1< i_2} {\bf P}(A_{i_1} A_{i_2}) + \cdots - (-1)^n{\bf P}(A_1 \cdots A_n).
$$
Эта формула называется формулой включений-исключений. Докажем её.
\begin{proof}
Будем действовать по индукции. Для $n=2$ она представляет указанное ранее свойство.

Пусть для $n=k$ формула доказана. Докажем ее для $n=k+1$. Пользуясь ей при $n=2$, получаем
$$
{\bf P}\left(\bigcup_{i\le k+1} A_i\right) = 
{\bf P}(A_1\cup A_2 \dotsm \cup A_{k}) + {\bf P}(A_{k+1}) - {\bf P}((A_1 A_{k+1})\cup \dotsm \cup (A_{k}A_{k+1})).
$$
Применяя предположение индукции, перепишем это выражение в виде
\begin{eqnarray*}
 \sum_{i\le k} {\bf P}(A_i) - \sum_{i_1< i_2\le k} {\bf P}(A_{i_1} A_{i_2})  + \dotsb - (-1)^{k} {\bf P}(A_1 \dotsm A_{k}) + {\bf P}(A_{k+1}) - 
 \sum_{i\le k} {\bf P}(A_i A_{k+1}) +\\
  \sum_{i_1< i_2\le k} {\bf P}(A_{i_1} A_{i_2} A_{k+1})  - \dotsb - (-1)^{k+1} {\bf P}(A_1 \dotsm A_{k+1}).
\end{eqnarray*}
Перегруппировывая слагаемые, получаем требуемое.
\end{proof}
Поскольку среди событий есть события $\{\omega_1\}$, $\dotsc$., $\{\omega_N\}$, то мы можем рассмотреть их вероятности $p_1,\dotsc, p_N$. Для любого события $A$, тем самым, мы получаем
$$
{\bf P}(A) = \sum_{i: \omega_i\in A} p_i = \sum_{i: \omega_i\in A} {\bf P}(\{\omega_i\}).
$$
Поэтому нам достаточно задать вероятности элементарных исходов $p_i$, вероятности всех остальных событий будут определяться этими числами. Вообще говоря, на роль $p_i$ подойдут любые неотрицательные числа, в сумме дающие $1$.

\begin{Def}
Итак, {\it вероятностным пространством} называется тройка $(\Omega,\mathcal{F},{\bf P})$ из пространства элементарных исходов, алгебры событий и вероятностной меры.
\end{Def}
В нашем простом случае мы, чаще всего, будем задавать $\Omega$, в качестве множества событий брать множество всех подмножеств $\Omega$, а вероятность на них будем задавать, исходя из вероятностей элементарных исходов $p_1,\dotsc, p_N$.
\subsubsection{Как выбрать вероятностное пространство}
Возникает важный вопрос --- как сопоставить эксперименту вероятностное пространство?

С $\Omega$ особых проблем не возникает --- мы просто должны сопоставить эксперименту подходящее описание в каком-то виде, закодировать итоги эксперимента. Хотя, как мы увидим позже, удачный выбор $\Omega$ иногда фактически решает задачу.

С $\mathcal{F}$ в текущей постановке все совсем просто --- обычно это будет просто множество всех подмножеств $\Omega$.

А вот с ${\bf P}$ возникают проблемы. Мы можем сопоставить элементарным исходам любые вероятности, лишь бы их сумма была равна 1. Но, вообще говоря, нам бы хотелось, чтобы теория соответствовала эксперименту. Пока мы плохо понимаем как именно, но каждому с детства понятен анекдот про блондинку, которая сопоставляет исходам ''встретить динозавра на улице'' и ''не встретить динозавра на улице'' равные вероятности. Это сопоставление вероятностей элементарным исходам не соответствует нашему представлению о реальных частотах этих событий. Пока мы постараемся обходить эту проблему и считать, что вероятности даны нам свыше. Впрочем, сегодня мы рассмотрим удачный частный случай, в котором понятно как составить вероятности элементарным исходам.

\subsection{Классическое вероятностное пространство}
\subsubsection{Общая постановка}
Если мы, например, бросаем игральный кубик, то естественно приписать этому эксперименту $\Omega = \{1,2,3,4,5,6\}$ и всех исходам приписать равные вероятности $1/6$, потому что все числа на кубике равноправны.
\begin{Def}
Говорят, что вероятности на пространстве элементарных исходов $\Omega$ заданы классически, если $p_i = {\bf P}(\omega_i) = 1/N$. 
\end{Def}
Вспоминая все тот же анекдот, мы видим, что разумно использовать классическое задание вероятностей только если у исходов есть симметрия. У наличия и отсутствия динозавра на улице такой симметрии нет.
\begin{Exam}
При двух бросания монеты мы можем рассмотреть $\Omega_1 = \{(0,0), (1,0), (0,1), (1,1)\}$ с $\mathcal{F}_1 = 2^{\Omega_1}$ и ${\bf P}_1(\omega_i) = 1/4$. 

А можем рассмотреть $\Omega_2 = \{\{0,0\}, \{1,0\}, \{1,1\}\}$ c $\mathcal{F}_2$ и ${\bf P}_2(\omega_i) = 1/3$. 

При этом пространства находятся в конфликте друг с другом --- одно и то же реальное событие ''два орла'' имеет в одном из них вероятность 1/4, а во втором 1/3. 

В первом симметрия исходов совершенно разумна --- при каждом из бросков орел и решка для нас равнозначны (если, конечно, монетку мы считаем честной). Во втором случае исход ''один раз выпала решка, а один орел'' совершенно не симметричен исходу ''дважды выпал орел''. Поэтому в первом случае классическое задание вероятностей соответствует постановке задачи, а во втором нет.
\end{Exam}
\subsubsection{Выбор шаров из урны}
Рассмотрим урну с шарами, пронумерованными от $1$ до $n$. Предположим, что мы вытягиваем $k$ шаров и записываем их номера. \\
\begin{enumerate}
\item Упорядоченный выбор с возвращением. Пусть номера записываются в порядке появления, а шары после каждого вытягивания возвращаются в урну. Тогда естественно использовать 
$$
\Omega = \{(i_1,\dotsc,i_k),\ i_1,\dotsc,i_k\in \{1,\dotsc,n\}\},\quad \mathcal{F} = 2^{\Omega}.
$$
При этом классически заданная вероятность соответствует нашим представлениям о задаче --- все раскладки шаров равновероятны просто потому, что каждый раз нам совершенно все равно что вытаскивать --- $1$, $2$, $\dotsc$ или $k$. 

Все возможные исходы представляют собой таблицу $\{1,\dotsc,n\}\times \dotsm \times \{1,\dotsc,n\}$, в которой $n^k$ исходов. Нам более удобно представить их в виде дерева, что легко позволяет убедиться в том, что $|\Omega| = n^k$, где $|\cdot|$ --- мощность множества. Действительно, каждая вершина на нижнем слое дерева соответствует одному набору $(i_1,\dotsc,i_k)$. Число вершин на нижнем слое при этом в n раз больше, чем на предыдущем, в том --- в n раз больше, чем на предыдущем и так далее (см. Рис~\ref{NoRepl}).
\begin{figure}[h!]
\caption{Упорядоченный выбор с возвращением}
\label{NoRepl}
   \begin{center}
   \includegraphics[width=15cm,height=8.5cm,keepaspectratio]{NoRepl.png}
   \end{center}
\end{figure}
\item Упорядоченный выбор без возвращения. Пусть номера записываются в порядке появления, а шары после каждого вытягивания откладываются. Тогда естественно использовать
$$
\Omega = \{(i_1,\dotsc,i_k),\ i_1,\dotsc,i_k\in \{1,\dotsc,n\},\ i_j\neq i_l, j\neq l\},\quad \mathcal{F} = 2^{\Omega}.
$$
При этом классически заданная вероятность соответствует нашим представлениям о задаче --- все раскладки шаров равновероятны просто потому, что каждый раз нам совершенно все равно какой из оставшихся шаров вытягивать.

Опять же удобно представить исходы в виде дерева, что легко позволяет убедиться в том, что $|\Omega| = n!/(n-k)! = A_n^k$.
\begin{figure}[h!]
\caption{Упорядоченный выбор без возвращения}
   \begin{center}
   \includegraphics[width=15cm,height=8.5cm,keepaspectratio]{Repl.png}
   \end{center}
\end{figure}
\begin{Que}
А сколько способов достать пять шаров из семи, если шары не возвращаются в урну, а их порядок неважен?
\end{Que}
\item Неупорядоченный выбор без возвращения. Пусть номера записываются без порядка, а шары после каждого вытягивания откладываются. Тогда естественно использовать
$$
\Omega = \{\{i_1,\dotsc,i_k\},\ i_1,\dotsc,i_k\in \{1,\dotsc,n\},\ i_j\neq i_l, j\neq l\},\quad \mathcal{F} = 2^{\Omega}.
$$
Здесь элементарный исход --- это множество из $k$ различных чисел от 1 до n, в котором порядок появления чисел уже не имеет значения. Значит, исходов станет меньше. 

Если попробовать сравнить упорядоченные и неупорядоченный исходы, то мы заметим, что каждому неупорядоченному исходу соответствуют k! упорядоченных, которые ему равносильны. Действительно, к неупорядоченному исходу $\{1,\dotsc,k\}$ приведут любые упорядоченные исходы, в которых используются те же числа. Способов упорядочить $\{1,\dotsc,k\}$ как раз k!, откуда неупорядоченных исходов в k! раз меньше. Значит,
$$
|\Omega| = C_n^k = \frac{1}{k!} A_n^k = \frac{n!}{k! (n-k)!}.
$$
\begin{figure}[h!]
\caption{Способы выбора трех предметов из четырех}
   \begin{center}
   \includegraphics[width=15cm,height=5cm,keepaspectratio]{ReplOrd.png}
   \end{center}
\end{figure}
Отметим, что упорядоченный и неупорядоченный выбор с возвращением соответствуют одной физической реальности, одинаковые события в обеих моделях имеют одинаковую вероятность.
\item Неупорядоченный выбор с возвращением. Пусть номера записываются без порядка, а шары после каждого вытягивания возвращаются в урну. Тогда зададим пространство немного в другом формате
$$
\Omega = \{(i_1,\dotsc,i_n),\ i_1+\dotsb+i_n=k\},\quad \mathcal{F} = 2^{\Omega}.
$$
Здесь элементарный исход --- это количество $i_1$ шаров с цифрой 1, количество $i_2$ шаров с цифрой 2,$\dotsc$, $i_n$ шаров с цифрой $n$.  

Сколько при этом исходов в $\Omega$? Давайте посмотрим на другую задачу с тем же пространством элементарных исходов: $k$ неразличимых предметов раскладываются по $n$ ящикам. Тогда если $i_1$ обозначить число предметов в первом ящике,$\dotsc$, $i_n$ --- в $n$-м ящике, то мы получим то же самое множество. 

\begin{figure}[h!]
\caption{Связь раскладок 4 шаров по 2 ящикам без пустых ящиков или 2 шаров по 2 ящикам с возможными пустыми. Правые раскладки получаются из левых изъятием зеленых шаров}
   \begin{center}
   \includegraphics[width=10cm,height=3.5cm,keepaspectratio]{NoReplNoOrd.png}
   \end{center}
\end{figure}

Чтобы решить эту задачу, решим сперва более простую --- пусть мы хотим разложить предметы по ящикам так, чтобы пустых ящиков не было. Это все равно, что поставить между $k$ предметами $n-1$ перегородку (стенку) будущих ящиков. Это все равно что выбрать из $k-1$ места $n-1$ без учета порядка. Мы умеем решать такую задачу, таких способов $C^{n-1}_{k-1}$.

Теперь вернемся к исходной задаче. Здесь уже нельзя так просто выбрать перегородки --- несколько из них могут встать на одну и ту же позицию. Давайте добавим к нашим $k$ предметам еще $n$ штук и заранее положим по одному из добавленных предметов в каждый из ящиков. Теперь уже пустых ящиков не будет. Каждой раскладке $k$ предметов по $n$ ящикам с возможными пустыми ящиками соответствует единственная раскладка $k+n$ предметов по $n$ ящикам без пустых ящиков. То есть у нашей задачи ответ $C_{n+k-1}^{n-1}$. 

Однако, вряд ли мы можем естественным образом выбрать в этом случае классическое задание вероятности, поскольку здесь мы не видим никакой симметрии между исходами. Скажем, при $n=k$ исход ''все шары имеют номер 1'' и исход ''все номера встречаются по одному разу'' не выглядят равнозначными, второй бывает гораздо чаще. Собственно, пример с двумя монетами, который мы уже рассматривали выше, является частным случаем этого эффекта.
\end{enumerate}
\begin{Exam}
Представим себе, что студент Иванов на экзамене знает $k$ билетов из $n$. Какая вероятность того, что он, стоя в очереди $m$-м, вытянет знакомый билет?

Этот опыт соответствует модели 2) --- упорядоченный выбор без возвращения. Соответственно, 
$$\Omega = \{(i_1,\dotsc,i_m),\ i_j\neq i_l,\ j\neq l\},\quad |\Omega|=A_m^n,\quad {\bf P}(\omega_j) = \frac{1}{A_m^n}.
$$
 Нас интересует событие $A=\{(i_1,\dotsc,i_m)\in \Omega: i_m \in \{1,\dotsc,k\}\}$. Аналогично тому, как мы нашли количество исходов в модели 2), мы можем понять, что 
 $$
 |A| = k\cdot (n-1) \dotsm (n-m+1), 
 $$
 поскольку билет для Иванова выбирается $k$ способами, для первого из студентов --- $n-1$ способом и так далее. Итого,
 $$
 {\bf P}(A) = \frac{|A|}{|\Omega|} = \frac{k(n-1)\dotsm(n-m+1)}{n(n-1)\dotsm(n-m+1)} = \frac kn.
 $$
 Как и следовало ожидать, Иванову совершенно неважно каким тянуть билет, шансы у него те же. В каких-то случаях его шансы вытянуть удачный билет повышаются, в каких-то понижаются, но все эти случаи волшебным образом воплощаются в той же вероятности, что и у первого студента.
 
Отметим, что здесь мы использовали такой прием --- в нашем словесном представлении исходной задачи нам трудно заставить сперва выбрать билет Иванова, а потом всех остальных. А вот в пространстве элементарных исходов мы считаем последовательности и нам совершенно неважно, в каком порядке пронумерованы их члены. Вероятностная модель позволила нам избавиться от лишних условностей, которыми нас связывает физическая постановка задачи.
\end{Exam}
\subsection{Ответы на вопросы}
\begin{enumerate}
\item (c), потому что два остальных события по существу включаются в в третье.
\item Событий станет 13. К 9 предыдущим события добавятся еще 4 --- ''монета потерялась при первом броске'', ''монета выпала на орла, а потом потерялась'', ''монета выпала на решку, а потом потерялась'', ''монета встала на ребро, а потом потерялась''.
\item Нет, неверно. Такие события не так уж часты, они называются независимыми, и мы поговорим о них на следующей лекции. В частности, если $A=B$, то мы придем к равенству только если ${\bf P}(A) = {\bf P}(A)^2$, то есть ${\bf P}(A)\in \{0,1\}$. Аналогично, если $AB=\emptyset$, то мы придем к равенству только если ${\bf P}(A)=0$ или ${\bf P}(B)=0$.
\item $C_7^5 = 7\cdot 6/2 = 21$.
\end{enumerate}
\end{document}
